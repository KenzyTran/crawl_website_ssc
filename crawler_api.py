from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
import os
import unicodedata
import sys

def setup_driver():
    options = webdriver.ChromeOptions()
    options.add_argument('--headless=new')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.set_page_load_timeout(30)
    return driver


def wait_for_element(driver, by_method, selector, timeout=20):
    """Ch·ªù element xu·∫•t hi·ªán tr√™n trang."""
    return WebDriverWait(driver, timeout).until(
        EC.presence_of_element_located((by_method, selector))
    )


def get_table_data(soup, selector):
    """Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ b·∫£ng HTML."""
    rows = soup.select(selector)
    data = []
    for tr in rows:
        tds = tr.find_all("td")
        row = [td.find("span").get_text(strip=True) if td.find("span") else "" for td in tds]
        if row:  # lo·∫°i b·ªè d√≤ng r·ªóng
            data.append(row)
    return data


def get_table_headers(driver, header_id):
    """L·∫•y ti√™u ƒë·ªÅ c√°c c·ªôt c·ªßa b·∫£ng."""
    header_table = driver.find_element(By.ID, header_id)
    header_html = header_table.get_attribute("outerHTML")
    header_soup = BeautifulSoup(header_html, "html.parser")
    
    header_tr = header_soup.select_one("tbody > tr:nth-of-type(2)")
    header_ths = header_tr.find_all("th")
    return [th.get_text(strip=True) for th in header_ths]


def click_tab(driver, tab_id):
    """Click v√†o tab theo ID."""
    tab = driver.find_element(By.ID, tab_id)
    driver.execute_script("arguments[0].scrollIntoView(true);", tab)
    time.sleep(1)  # ƒë·ªÉ ·ªïn ƒë·ªãnh
    driver.execute_script("arguments[0].click();", tab)
    time.sleep(2)  # ƒë·∫£m b·∫£o render xong


def strip_accents(text: str) -> str:
    nfkd = unicodedata.normalize('NFD', text)
    return ''.join(ch for ch in nfkd if unicodedata.category(ch) != 'Mn')

def extract_quarter_year(report_name: str) -> str:
    """
    - B√°o c√°o b√°n ni√™n YYYY  ‚Üí H1.YYYY
    - B√°o c√°o nƒÉm YYYY      ‚Üí YYYYY
    - Qu√Ω N[/ ]YYYY         ‚Üí QN.YYYY
    fallback ‚Äúunknown‚Äù n·∫øu kh√¥ng t√¨m th·∫•y s·ªë nƒÉm/qu√Ω
    """
    name = strip_accents(report_name)

    # 1) B√°n ni√™n YYYY
    m = re.search(r'ban nien\s*(\d{4})', name, re.IGNORECASE)
    if m:
        return f"H1.{m.group(1)}"

    # 2) B√°o c√°o t√†i ch√≠nh nƒÉm YYYY
    m = re.search(r'\bnam\s*(\d{4})', name, re.IGNORECASE)
    if m:
        return f"Y{m.group(1)}"

    # 3) Qu√Ω N[/ ]YYYY ho·∫∑c Qu√Ω N nƒÉm YYYY
    for pattern in (r'\bquy\s*(\d+)[/ ]*(\d{4})',
                    r'\bquy\s*(\d+)[/ ]*nam\s*(\d{4})'):
        m = re.search(pattern, name, re.IGNORECASE)
        if m:
            return f"Q{m.group(1)}.{m.group(2)}"

    # 4) Ch∆∞a r√µ nƒÉm/qu√Ω ‚Üí fallback
    return "unknown"


def extract_quarter_year_from_detail(driver):
    """Tr√≠ch xu·∫•t th√¥ng tin qu√Ω v√† nƒÉm t·ª´ chi ti·∫øt b√°o c√°o, b·ªè qua m·ªçi d·∫•u v√† kh√¥ng ph·ª• thu·ªôc ID c·ªë ƒë·ªãnh."""
    def strip_accents(text: str) -> str:
        # chuy·ªÉn v·ªÅ NFD r·ªìi lo·∫°i b·ªè c√°c k√Ω t·ª± d·∫•u (Mn)
        nfkd = unicodedata.normalize('NFD', text)
        return ''.join(ch for ch in nfkd if unicodedata.category(ch) != 'Mn')
    
    try:
        div_html = driver.find_element(By.ID, "pt2:tt1::db").get_attribute("outerHTML")
        soup = BeautifulSoup(div_html, "html.parser")

        year = None
        quarter = None

        # duy·ªát qua t·ª´ng <tr> trong b·∫£ng
        for tr in soup.select("tr"):
            tds = tr.find_all("td")
            if len(tds) < 3:
                continue

            raw_label = tds[0].get_text(strip=True)
            raw_value = tds[2].get_text(strip=True)

            # chu·∫©n h√≥a (b·ªè d·∫•u, lowercase)
            label = strip_accents(raw_label).lower()
            value = raw_value.strip()

            # n·∫øu nh√£n ch·ª©a "nam" v√† ch∆∞a t√¨m th·∫•y nƒÉm
            if "nam" in label and not year:
                m = re.search(r"\d{4}", value)
                if m:
                    year = m.group()

            # n·∫øu nh√£n ch·ª©a "quy" v√† ch∆∞a t√¨m th·∫•y qu√Ω
            if "quy" in label and not quarter:
                m = re.search(r"\d+", value)
                if m:
                    quarter = m.group()

            # n·∫øu ƒë√£ c√≥ c·∫£ 2 th√¨ d·ª´ng s·ªõm
            if year and quarter:
                break

        if year and quarter:
            return f"Q{quarter}.{year}"
        if year:
            return f"Y{year}"
        return "unknown"

    except Exception as e:
        print(f"L·ªói khi tr√≠ch xu·∫•t qu√Ω/nƒÉm: {e}")
        return "unknown"


def should_skip_based_on_h1(driver):
    """Ki·ªÉm tra xem c√≥ n√™n b·ªè qua b√°o c√°o n√†y d·ª±a tr√™n n·ªôi dung th·∫ª h1 trong div pt2:pb2."""
    try:
        # T√¨m div v·ªõi id pt2:pb2
        div_element = driver.find_element(By.ID, "pt2:pb2")
        
        # T√¨m th·∫ª h1 trong div ƒë√≥
        h1_elements = div_element.find_elements(By.TAG_NAME, "h1")
        
        if h1_elements:
            h1_text = h1_elements[0].text.strip()
            
            # Danh s√°ch t·ª´ kh√≥a lo·∫°i tr·ª´
            exclude_keywords = ["M·∫π", "m·∫π", "Ri√™ng"]
            
            # Ki·ªÉm tra n·∫øu h1 ch·ª©a b·∫•t k·ª≥ t·ª´ kh√≥a n√†o c·∫ßn lo·∫°i tr·ª´
            for keyword in exclude_keywords:
                if keyword in h1_text:
                    print(f"‚è≠Ô∏è B·ªè qua b√°o c√°o v√¨ h1 c√≥ ch·ª©a t·ª´ kh√≥a '{keyword}': '{h1_text}'")
                    return True
        
        return False
    except Exception as e:
        print(f"L·ªói khi ki·ªÉm tra h1: {e}")
        # N·∫øu c√≥ l·ªói, kh√¥ng b·ªè qua b√°o c√°o
        return False


def process_table_data(driver, header_id, data_id, tab_name):
    """L·∫•y v√† x·ª≠ l√Ω d·ªØ li·ªáu c·ªßa m·ªôt b·∫£ng."""
    try:
        # L·∫•y headers
        headers = get_table_headers(driver, header_id)
        print(f"\nüßæ T√™n c√°c c·ªôt {tab_name}:", headers)
        
        # L·∫•y d·ªØ li·ªáu b·∫£ng
        data_div = driver.find_element(By.ID, data_id)
        data_html = data_div.get_attribute("outerHTML")
        data_soup = BeautifulSoup(data_html, "html.parser")
        
        data = get_table_data(data_soup, "tbody > tr")
        
        # T·∫°o DataFrame
        return pd.DataFrame(data, columns=headers)
    except Exception as e:
        print(f"L·ªói khi x·ª≠ l√Ω b·∫£ng {tab_name}: {e}")
        return pd.DataFrame()  # Tr·∫£ v·ªÅ DataFrame r·ªóng n·∫øu c√≥ l·ªói


def process_report_detail(driver, report_index, report_name, quarter_year, stock_code):
    """X·ª≠ l√Ω chi ti·∫øt b√°o c√°o v√† l·∫•y d·ªØ li·ªáu t·ª´ c√°c tab."""
    print(f"\n\n=== ƒêang x·ª≠ l√Ω b√°o c√°o {report_index + 1}: {report_name} ===")
    
    try:
        # Ch·ªù trang chi ti·∫øt
        wait_for_element(driver, By.ID, "pt2:pt1::tabbc")
        time.sleep(2)
        
        # Ki·ªÉm tra h1 trong div pt2:pb2
        if should_skip_based_on_h1(driver):
            print(f"‚ùå B·ªè qua b√°o c√°o {report_name} d·ª±a tr√™n n·ªôi dung h1")
            return False
        
        # N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin qu√Ω/nƒÉm t·ª´ t√™n b√°o c√°o, th·ª≠ tr√≠ch xu·∫•t t·ª´ chi ti·∫øt
        if quarter_year == "unknown":
            quarter_year = extract_quarter_year_from_detail(driver)
            print(f"Th√¥ng tin qu√Ω/nƒÉm t·ª´ chi ti·∫øt b√°o c√°o: {quarter_year}")
        
        # L·∫•y m√£ ƒë·ªãnh danh l√†m ti·ªÅn t·ªë t√™n file
        mdn_value = driver.find_element(By.CSS_SELECTOR, "td.xth.xtk").text.strip()
        id_mack = re.sub(r'[\\/*?:"<>|]', "_", mdn_value)
        
        # T·∫°o th∆∞ m·ª•c ƒë·ªÉ l∆∞u d·ªØ li·ªáu c·ªßa m√£ ch·ª©ng kho√°n n√†y theo qu√Ω
        if quarter_year == "unknown":
            # N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin qu√Ω, s·ª≠ d·ª•ng th∆∞ m·ª•c m·∫∑c ƒë·ªãnh
            report_dir = f"data/{stock_code}"
        else:
            # N·∫øu t√¨m th·∫•y th√¥ng tin qu√Ω, t·∫°o th∆∞ m·ª•c theo qu√Ω
            report_dir = f"{quarter_year}/{stock_code}"
        
        os.makedirs(report_dir, exist_ok=True)
        
        # X·ª≠ l√Ω b·∫£ng CDKT (b·∫£ng m·∫∑c ƒë·ªãnh)
        df_cdkt = process_table_data(driver, "pt2:t2::ch::t", "pt2:t2::db", "CDKT")
        if not df_cdkt.empty:
            df_cdkt.to_csv(f"{report_dir}/{id_mack}_baocao_cdkt.csv", index=False, encoding='utf-8-sig')
            print(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu CDKT v√†o {report_dir}")
        
        # X·ª≠ l√Ω b·∫£ng KQKD
        click_tab(driver, "pt2:KQKD::disAcr")
        df_kqkd = process_table_data(driver, "pt2:t3::ch::t", "pt2:t3::db", "KQKD")
        if not df_kqkd.empty:
            df_kqkd.to_csv(f"{report_dir}/{id_mack}_baocao_kqkd.csv", index=False, encoding='utf-8-sig')
            print(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu KQKD v√†o {report_dir}")
        
        # X·ª≠ l√Ω b·∫£ng LCTT-TT
        click_tab(driver, "pt2:LCTT-TT::disAcr")
        df_lctt_tt = process_table_data(driver, "pt2:t5::ch::t", "pt2:t5::db", "LCTT-TT")
        if not df_lctt_tt.empty:
            df_lctt_tt.to_csv(f"{report_dir}/{id_mack}_baocao_lctt_tt.csv", index=False, encoding='utf-8-sig')
            print(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu LCTT-TT v√†o {report_dir}")
        
        # X·ª≠ l√Ω b·∫£ng LCTT-GT
        click_tab(driver, "pt2:LCTT-GT::disAcr")
        df_lctt_gt = process_table_data(driver, "pt2:t6::ch::t", "pt2:t6::db", "LCTT-GT")
        if not df_lctt_gt.empty:
            df_lctt_gt.to_csv(f"{report_dir}/{id_mack}_baocao_lctt_gt.csv", index=False, encoding='utf-8-sig')
            print(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu LCTT-GT v√†o {report_dir}")
        
        return True
    except Exception as e:
        print(f"L·ªói khi x·ª≠ l√Ω chi ti·∫øt b√°o c√°o: {e}")
        return False


def should_skip_report(report_name):
    """Ki·ªÉm tra xem c√≥ n√™n b·ªè qua b√°o c√°o n√†y kh√¥ng d·ª±a tr√™n t√™n."""
    # Danh s√°ch t·ª´ kh√≥a lo·∫°i tr·ª´
    exclude_keywords = ["M·∫π", "m·∫π", "Ri√™ng"]
    
    # Ki·ªÉm tra n·∫øu t√™n b√°o c√°o ch·ª©a b·∫•t k·ª≥ t·ª´ kh√≥a n√†o c·∫ßn lo·∫°i tr·ª´
    for keyword in exclude_keywords:
        if keyword in report_name:
            return True
    
    return False


def get_report_links(driver):
    """
    L·∫•y t·∫•t c·∫£ c√°c b√°o c√°o tr√™n page hi·ªán t·∫°i b·∫±ng c√°ch query
    tr·ª±c ti·∫øp c√°c <a> ch·ª©a ID k·∫øt th√∫c b·∫±ng ':cl1', b·ªè qua ones b·ªã l·ªçc.
    Tr·∫£ v·ªÅ list c√°c tuple (global_index, link_id, report_name, quarter_year).
    """
    reports = []
    skipped = 0

    # 1) T√¨m table ch·ª©a danh s√°ch
    table = wait_for_element(driver, By.ID, "pt9:t1::db")
    # 2) L·∫•y t·∫•t c·∫£ <a> c√≥ id k·∫øt th√∫c b·∫±ng ':cl1'
    link_els = table.find_elements(By.CSS_SELECTOR, "a[id$=':cl1']")
    
    for el in link_els:
        link_id = el.get_attribute("id")
        report_name = el.text.strip()
        
        # Ki·ªÉm skip theo keyword
        if should_skip_report(report_name):
            skipped += 1
            print(f"‚è≠Ô∏è B·ªè qua '{report_name}'")
            continue
        
        # Tr√≠ch qu√Ω/nƒÉm
        quarter_year = extract_quarter_year(report_name)
        # L·∫•y index to√†n c·ª•c t·ª´ ID: pt9:t1:<idx>:cl1
        idx = int(link_id.split(":")[2])
        
        reports.append((idx, link_id, report_name, quarter_year))
        print(f"‚úÖ ID={idx}, {report_name} ‚Üí {quarter_year}")

    print(f"ƒê√£ b·ªè qua {skipped} b√°o c√°o theo t·ª´ kh√≥a l·ªçc")
    return reports


def main(stock_code="PVS"):
    driver = setup_driver()
    try:
        # 1. M·ªü trang v√† search
        driver.get("https://congbothongtin.ssc.gov.vn/faces/NewsSearch")
        wait_for_element(driver, By.ID, "pt9:it8112::content").send_keys(stock_code)
        driver.find_element(By.XPATH, "//span[text()='T√¨m ki·∫øm']/ancestor::a")\
              .click()
        wait_for_element(driver, By.ID, "pt9:t1::db")
        time.sleep(2)

        # 2. L·∫•y t·ªïng s·ªë b√°o c√°o
        initial_reports = get_report_links(driver)
        total = len(initial_reports)

        # 3. Duy·ªát theo index
        for i in range(total):
            # m·ªói v√≤ng l·∫∑p re-fetch link list ƒë·ªÉ c√≥ ID m·ªõi
            reports = get_report_links(driver)
            idx, link_id, report_name, quarter_year = reports[i]

            # click v√†o b√°o c√°o th·ª© i
            el = driver.find_element(By.ID, link_id)
            driver.execute_script("arguments[0].scrollIntoView(true);", el)
            time.sleep(0.5)
            el.click()

            # x·ª≠ l√Ω detail nh∆∞ b√¨nh th∆∞·ªùng
            process_report_detail(driver, idx, report_name, quarter_year, stock_code)

            # quay l·∫°i k·∫øt qu·∫£ t√¨m ki·∫øm
            driver.back()
            wait_for_element(driver, By.ID, "pt9:t1::db")
            time.sleep(1)

    finally:
        driver.quit()



if __name__ == "__main__":
    if len(sys.argv) >= 2:
        stock = sys.argv[1]
    else:
        stock = "PVS"

    main(stock)